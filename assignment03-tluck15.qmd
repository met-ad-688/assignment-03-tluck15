---
title: Assignment 03
author:
  - name: Taylor Luckenbill
    affiliations:
      - id: bu
        name: Boston University
        city: Boston
        state: MA
number-sections: true
date: '2024-11-21'
format:
  html:
    theme: cerulean
    toc: true
    toc-depth: 2
date-modified: today
date-format: long
execute:
  echo: false
  eval: false
  freeze: auto
jupyter: python3
---


```{python}
import pandas as pd
import plotly.express as px
import plotly.io as pio
from pyspark.sql import SparkSession
import re
import numpy as np
import plotly.graph_objects as go
from pyspark.sql.functions import col, split, explode, regexp_replace, transform, when
from pyspark.sql import functions as F
from pyspark.sql.functions import col, monotonically_increasing_id
```

```{python}
np.random.seed(2)

pio.renderers.default = "notebook"

# Initialize Spark Session
spark = SparkSession.builder.appName("LightcastData").getOrCreate()

# Load Data
df = spark.read.option("header", "true").option("inferSchema", "true").option("multiLine","true").option("escape", "\"").csv("data/lightcast_job_postings.csv")
df.createOrReplaceTempView("job_postings")

# Show Schema and Sample Data
#print("---This is Diagnostic check, No need to print it in the final doc---")

#df.printSchema() # comment this line when rendering the submission
df.show(5)
```

```{python}
filtered_df = df.filter(col("SALARY").isNotNull() 
                        & (col("SALARY") != 0) 
                        & col("MIN_YEARS_EXPERIENCE").isNotNull() )
filtered_df.show(30)
```

```{python}
grouped_df_pd = filtered_df.toPandas()

grouped_df_pd = (
    grouped_df_pd
    .groupby("MIN_YEARS_EXPERIENCE")
    .agg(
        median_salary=("SALARY", "median"),
        count=("ID", "count")
    )
    .reset_index()
)

grouped_df_pd.head(20)
```

